
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7.4. The QR algorithm for finding eigenvalues and eigenvectors &#8212; Linear Algebra for Data Workbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="7.3. The Eigenvalue decomposition for special types of matrices" href="eigenstuff_eigenthings-special-matrices.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Linear Algebra for Data Workbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Welcome to Stat 89A
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="python_chheader.html">
   1. Python 101
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="python_basics.html">
     1.1. The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_numpy.html">
     1.2. Introduction to NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_plotting.html">
     1.3. MatPlotLib
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic Linear Algebra
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_1_chheader.html">
   2. Matrices, vectors, and
   <span class="math notranslate nohighlight">
    \(\mathbb{R}^n\)
   </span>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_introduction-to-norms.html">
     2.1. Introduction to Norms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_norms-integration-monte-carlo.html">
     2.2. An application: approximating integrals with norms and Monte Carlo integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_lp-balls.html">
     2.3.
     <span class="math notranslate nohighlight">
      \(\ell_p\)
     </span>
     Balls
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_classification-with-norms.html">
     2.4. An application: classifying data points using norms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_2_chheader.html">
   3. Basics of vectors and vector spaces
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_2A_vectorspaces.html">
     3.1. Vectors and vector spaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_3_chheader.html">
   4. Basics of matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_matrices-and-matrix-operations.html">
     4.1. Matrices and matrix operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_deconstructing.html">
     4.2. Deconstructing Matrix Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_powers_of_matrices.html">
     4.3. Taking Powers of Matrices
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_3B_chheader.html">
   5. Matrices as transformations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_linear_examples_new.html">
     5.1. Linear and Nonlinear Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_matrices_and_linear_functions.html">
     5.2. Matrices and Linear Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_injective-and-surjective-functions.html">
     5.3. Injective, surjective and invertible functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_inverses.html">
     5.4. Left Inverses, Right Inverses, and Inverses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_changing_basis.html">
     5.5. Changing Basis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_4_chheader.html">
   6. Geometry: angles, orthogonality, and projections
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_dot-products-and-angles.html">
     6.1. Dot products, angles, and orthogonality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_QR.html">
     6.2. Gram–Schmidt and the QR Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_QR_linear_systems.html">
     6.3. Solving linear systems with the QR decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_projections.html">
     6.4. Projections
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Eigenthings, the spectral theorem, and the singular value decomposition
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="eigenstuff_chheader.html">
   7. Eigenstuff
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_quadratic-forms.html">
     7.1. Quadratic forms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_eigenthings.html">
     7.2. Eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_eigenthings-special-matrices.html">
     7.3. The Eigenvalue decomposition for special types of matrices
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     7.4. The QR algorithm for finding eigenvalues and eigenvectors
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/content/eigenstuff_qr-algorithm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/eigenstuff_qr-algorithm.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/erichson/LinearAlgebra/master?urlpath=tree/content/eigenstuff_qr-algorithm.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>The QR algorithm for finding eigenvalues and eigenvectors</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="the-qr-algorithm-for-finding-eigenvalues-and-eigenvectors">
<h1><span class="section-number">7.4. </span>The QR algorithm for finding eigenvalues and eigenvectors<a class="headerlink" href="#the-qr-algorithm-for-finding-eigenvalues-and-eigenvectors" title="Permalink to this headline">¶</a></h1>
<p>In the previous sections, we discussed finding the eigenvalues and eigenvectors of a matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> largely abstractly, without much interest in how we would actually do this in practice. As we saw, we can find the eigenvalues (in theory) by finding the zeros of the degree-<span class="math notranslate nohighlight">\(n\)</span> polynomial <span class="math notranslate nohighlight">\(p(\lambda) = \det(\boldsymbol{A} - \lambda \boldsymbol{I})\)</span>. If we had these eigenvalues, say <span class="math notranslate nohighlight">\(\lambda_1,\dots, \lambda_n\)</span>, then we could find the eigenvectors fairly easily by solving the linear system of equations</p>
<div class="math notranslate nohighlight">
\[
(\boldsymbol{A} - \lambda_i \boldsymbol{I})\boldsymbol{v} = 0,
\]</div>
<p>e.g. by using the QR decomposition and backsubstitution. The latter component would be a feasible way to find the eigenvectors in practice if we knew what the eigenvalues were. Unfortunately, finding the zeros of <span class="math notranslate nohighlight">\(p(\lambda)\)</span> this is not a particularly practical approach, beyond the 2- or 3-dimensional case. Instead, we require other algorithms to find the eigenvalues. We saw one method on the homework for doing this called the <em>power method</em>. Here we briefly introduce another popular algorithm which uses the QR decomposition called the QR algorithm, which we outline below.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
&amp;\underline{\textbf{QR algorithm}: \text{find the eigenvalues of an $n\times n$ matrix $\boldsymbol{A}$}} \\
&amp;\textbf{input}:\text{$n\times n$ matrix }\boldsymbol{A}\in \mathbb{R}^{n\times n} \\
&amp;\hspace{0mm} \text{while $\boldsymbol{A}$ is not approximately upper triangular:}\\
&amp;\hspace{10mm} \boldsymbol{Q}, \boldsymbol{R} = \texttt{qr_decomposition}(\boldsymbol{A})\\
&amp;\hspace{10mm} \text{update }\boldsymbol{A} = \boldsymbol{R}\boldsymbol{Q}\\
&amp;\hspace{0mm} \text{return } \text{diag}(\boldsymbol{A})\\
\end{align}
\end{split}\]</div>
<p>This algorithm works due to the following two properties. First, note that for a single interation we have</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{A}' = \boldsymbol{RQ} = \boldsymbol{Q^\top Q R Q} = \boldsymbol{Q}^\top \boldsymbol{AQ}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{Q}\)</span> is an orthogonal matrix. Because the matrices <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{A}'\)</span> differ only by an orthogonal transformation on either side, they are what we call <em>similar</em> matrices. It turns out that similar matrices always have the same eigenvalues. To see this, let <span class="math notranslate nohighlight">\((\lambda, \boldsymbol{v})\)</span> be an eigenvalue/eigenvector pair for <span class="math notranslate nohighlight">\(\boldsymbol{A}'\)</span>, and let <span class="math notranslate nohighlight">\(\boldsymbol{A} = \boldsymbol{Q\boldsymbol{A}'\boldsymbol{Q}}\)</span> be defined as above. Then</p>
<div class="math notranslate nohighlight">
\[
\lambda\boldsymbol{v} = \boldsymbol{A}'\boldsymbol{v} = \boldsymbol{QA Q^\top v} \iff \lambda \boldsymbol{Q^\top v} = \boldsymbol{A Q^\top v}.
\]</div>
<p>This means that <span class="math notranslate nohighlight">\((\lambda, \boldsymbol{Q^\top v})\)</span> is an eigenvalue/eigenvector pair for the matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>, and so <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{A}'\)</span> have the same eigenvalues, and eigenvectors which differ by a factor of <span class="math notranslate nohighlight">\(\boldsymbol{Q}^\top\)</span>. Thus at each iteration in the QR algorithm, the matrices <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> have the same eigenvalues.</p>
<p>The next step we do not prove, but will show numerically. It turns out that for “nice” matrices (in particular, matrices that have distinct eigenvalues), the QR algorithm converges to an upper triangular matrix. Therefore, as we saw in the previous section, we can read off the eigenvalues of this matrix by checking its diagonal entries. Let’s see a simple example that illustrates this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">Q</span><span class="p">,</span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">,</span><span class="n">Q</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;A at iteration i = </span><span class="si">%s</span><span class="s1"> is&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A at iteration i = 0 is
[[ 7.63442441 -0.92694129  0.7304525 ]
 [-0.92694129  0.88590248 -0.29370486]
 [ 0.7304525  -0.29370486  0.68681347]]
A at iteration i = 1 is
[[ 7.8381613  -0.12796439 -0.051322  ]
 [-0.12796439  0.8453167   0.13320343]
 [-0.051322    0.13320343  0.52366236]]
A at iteration i = 2 is
[[ 7.84086186e+00 -1.53177041e-02  3.25020496e-03]
 [-1.53177041e-02  8.75823397e-01 -7.69453274e-02]
 [ 3.25020496e-03 -7.69453274e-02  4.90455103e-01]]
A at iteration i = 3 is
[[ 7.84089669e+00 -1.76707214e-03 -1.99732103e-04]
 [-1.76707214e-03  8.86253517e-01  4.21671094e-02]
 [-1.99732103e-04  4.21671094e-02  4.79990160e-01]]
A at iteration i = 4 is
[[ 7.84089714e+00 -2.01611322e-04  1.21619825e-05]
 [-2.01611322e-04  8.89338940e-01 -2.26906416e-02]
 [ 1.21619825e-05 -2.26906416e-02  4.76904287e-01]]
A at iteration i = 5 is
[[ 7.84089714e+00 -2.29288759e-05 -7.38585895e-07]
 [-2.29288759e-05  8.90227735e-01  1.21450846e-02]
 [-7.38585896e-07  1.21450846e-02  4.76015487e-01]]
A at iteration i = 6 is
[[ 7.84089714e+00 -2.60526133e-06  4.48192637e-08]
 [-2.60526133e-06  8.90481976e-01 -6.49065443e-03]
 [ 4.48192648e-08 -6.49065443e-03  4.75761246e-01]]
A at iteration i = 7 is
[[ 7.84089714e+00 -2.95941416e-07 -2.71914986e-09]
 [-2.95941416e-07  8.90554559e-01  3.46725797e-03]
 [-2.71915090e-09  3.46725797e-03  4.75688663e-01]]
A at iteration i = 8 is
[[ 7.84089714e+00 -3.36145767e-08  1.64957481e-10]
 [-3.36145767e-08  8.90575269e-01 -1.85195111e-03]
 [ 1.64958514e-10 -1.85195111e-03  4.75667953e-01]]
A at iteration i = 9 is
[[ 7.84089714e+00 -3.81803810e-09 -1.00060702e-11]
 [-3.81803810e-09  8.90581177e-01  9.89139136e-04]
 [-1.00071041e-11  9.89139136e-04  4.75662045e-01]]
</pre></div>
</div>
</div>
</div>
<p>As we can see, the lower triangular portion of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> is becoming closer and closer to zero after more iterations. Hence, since the eigenvalues are unchanged at each iteration, we can read of the eigenvalues of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> from the eigenvalues of the (approximately) triangular matrix that we get after several iterations. Let’s now implement our own <code class="docutils literal notranslate"><span class="pre">eigenvalue_decomposition_qr</span></code> function which uses the QR algorthm to find the eigenvalues, and then finds the eigenvectors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">solve_triangular</span>

<span class="k">def</span> <span class="nf">eigenvalue_decomposition_qr</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    find the eigenvalues and eigenvectors of a matrix using the QR decomposition</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">A0</span> <span class="o">=</span> <span class="n">A</span>

    <span class="c1"># first implement the QR algorithm</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">A0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">A0</span><span class="p">)):</span>
        <span class="n">Q</span><span class="p">,</span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A0</span><span class="p">)</span>
        <span class="n">A0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="p">)</span>

    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">A0</span><span class="p">)</span>

    <span class="c1"># next, find the eigenvectors</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># use the QR decomposition to solve (A-\lambda I)v = 0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="n">vi</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vi</span><span class="p">)</span>

    <span class="c1"># shape the vectors into a matrix</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">vectors</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s test our implementation against the usual numpy <code class="docutils literal notranslate"><span class="pre">eig</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

<span class="n">values_qr</span><span class="p">,</span> <span class="n">vectors_qr</span> <span class="o">=</span> <span class="n">eigenvalue_decomposition_qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">values_qr</span><span class="p">)</span>

<span class="n">values</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[19.01157395 11.94476713  3.11049544  1.23164995  0.70103717]
[19.01157395 11.94476713  3.11049544  0.70103717  1.23164995]
</pre></div>
</div>
</div>
</div>
<p>Indeed, the two algorithms give the same output (though potentially not ordered in the same way).</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="eigenstuff_eigenthings-special-matrices.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">7.3. </span>The Eigenvalue decomposition for special types of matrices</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Michael W. Mahoney, N. Benjamin Erichson and Ryan Theisen<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>